cp -rf py3.10/examples .
cp -rf py3.10/doc .
cp -f py3.10/index.html .
cp -rf py3.10/_multiprocess _multiprocess
cp -rf py3.10/multiprocess multiprocess 
cp -rf py3.10/Modules/_multiprocess Modules/_multiprocess
# ----------------------------------------------------------------------
diff Python-3.10.0rc2/Lib/multiprocessing/connection.py Python-3.11.0a1/Lib/multiprocessing/connection.py
946c946
< # Make connection and socket objects sharable if possible
---
> # Make connection and socket objects shareable if possible
diff Python-3.10.0rc2/Lib/multiprocessing/managers.py Python-3.11.0a1/Lib/multiprocessing/managers.py
1341d1340
<             pass
# ----------------------------------------------------------------------
diff Python-3.10.0rc2/Lib/test/_test_multiprocessing.py Python-3.11.0a1/Lib/test/_test_multiprocessing.py 
613a614
>         gc.collect()  # For PyPy or other GCs.
2669a2671
>         gc.collect()  # For PyPy or other GCs.
3773a3776,3781
>     def _new_shm_name(self, prefix):
>         # Add a PID to the name of a POSIX shared memory object to allow
>         # running multiprocessing tests (test_multiprocessing_fork,
>         # test_multiprocessing_spawn, etc) in parallel.
>         return prefix + str(os.getpid())
> 
3775c3783,3784
<         sms = shared_memory.SharedMemory('test01_tsmb', create=True, size=512)
---
>         name_tsmb = self._new_shm_name('test01_tsmb')
>         sms = shared_memory.SharedMemory(name_tsmb, create=True, size=512)
3779c3788
<         self.assertEqual(sms.name, 'test01_tsmb')
---
>         self.assertEqual(sms.name, name_tsmb)
3787,3793d3795
<         # Test pickling
<         sms.buf[0:6] = b'pickle'
<         pickled_sms = pickle.dumps(sms)
<         sms2 = pickle.loads(pickled_sms)
<         self.assertEqual(sms.name, sms2.name)
<         self.assertEqual(bytes(sms.buf[0:6]), bytes(sms2.buf[0:6]), b'pickle')
< 
3799c3801
<         also_sms = shared_memory.SharedMemory('test01_tsmb')
---
>         also_sms = shared_memory.SharedMemory(name_tsmb)
3804c3806
<         same_sms = shared_memory.SharedMemory('test01_tsmb', size=20*sms.size)
---
>         same_sms = shared_memory.SharedMemory(name_tsmb, size=20*sms.size)
3822c3824
<             names = ['test01_fn', 'test02_fn']
---
>             names = [self._new_shm_name('test01_fn'), self._new_shm_name('test02_fn')]
3843a3846,3851
>             name_dblunlink = self._new_shm_name('test01_dblunlink')
>             sms_uno = shared_memory.SharedMemory(
>                 name_dblunlink,
>                 create=True,
>                 size=5000
>             )
3845,3850d3852
<                 sms_uno = shared_memory.SharedMemory(
<                     'test01_dblunlink',
<                     create=True,
<                     size=5000
<                 )
< 
3854c3856
<                     sms_duo = shared_memory.SharedMemory('test01_dblunlink')
---
>                     sms_duo = shared_memory.SharedMemory(name_dblunlink)
3866c3868
<                 'test01_tsmb',
---
>                 name_tsmb,
3880c3882
<             ok_if_exists_sms = OptionalAttachSharedMemory('test01_tsmb')
---
>             ok_if_exists_sms = OptionalAttachSharedMemory(name_tsmb)
3891a3894,3916
>     def test_shared_memory_recreate(self):
>         # Test if shared memory segment is created properly,
>         # when _make_filename returns an existing shared memory segment name
>         with unittest.mock.patch(
>             'multiprocessing.shared_memory._make_filename') as mock_make_filename:
> 
>             NAME_PREFIX = shared_memory._SHM_NAME_PREFIX
>             names = ['test01_fn', 'test02_fn']
>             # Prepend NAME_PREFIX which can be '/psm_' or 'wnsm_', necessary
>             # because some POSIX compliant systems require name to start with /
>             names = [NAME_PREFIX + name for name in names]
> 
>             mock_make_filename.side_effect = names
>             shm1 = shared_memory.SharedMemory(create=True, size=1)
>             self.addCleanup(shm1.unlink)
>             self.assertEqual(shm1._name, names[0])
> 
>             mock_make_filename.side_effect = names
>             shm2 = shared_memory.SharedMemory(create=True, size=1)
>             self.addCleanup(shm2.unlink)
>             self.assertEqual(shm2._name, names[1])
> 
>     def test_invalid_shared_memory_cration(self):
3903a3929,3969
>     def test_shared_memory_pickle_unpickle(self):
>         for proto in range(pickle.HIGHEST_PROTOCOL + 1):
>             with self.subTest(proto=proto):
>                 sms = shared_memory.SharedMemory(create=True, size=512)
>                 self.addCleanup(sms.unlink)
>                 sms.buf[0:6] = b'pickle'
> 
>                 # Test pickling
>                 pickled_sms = pickle.dumps(sms, protocol=proto)
> 
>                 # Test unpickling
>                 sms2 = pickle.loads(pickled_sms)
>                 self.assertIsInstance(sms2, shared_memory.SharedMemory)
>                 self.assertEqual(sms.name, sms2.name)
>                 self.assertEqual(bytes(sms.buf[0:6]), b'pickle')
>                 self.assertEqual(bytes(sms2.buf[0:6]), b'pickle')
> 
>                 # Test that unpickled version is still the same SharedMemory
>                 sms.buf[0:6] = b'newval'
>                 self.assertEqual(bytes(sms.buf[0:6]), b'newval')
>                 self.assertEqual(bytes(sms2.buf[0:6]), b'newval')
> 
>                 sms2.buf[0:6] = b'oldval'
>                 self.assertEqual(bytes(sms.buf[0:6]), b'oldval')
>                 self.assertEqual(bytes(sms2.buf[0:6]), b'oldval')
> 
>     def test_shared_memory_pickle_unpickle_dead_object(self):
>         for proto in range(pickle.HIGHEST_PROTOCOL + 1):
>             with self.subTest(proto=proto):
>                 sms = shared_memory.SharedMemory(create=True, size=512)
>                 sms.buf[0:6] = b'pickle'
>                 pickled_sms = pickle.dumps(sms, protocol=proto)
> 
>                 # Now, we are going to kill the original object.
>                 # So, unpickled one won't be able to attach to it.
>                 sms.close()
>                 sms.unlink()
> 
>                 with self.assertRaises(FileNotFoundError):
>                     pickle.loads(pickled_sms)
> 
4085c4151,4152
<         sl_copy = shared_memory.ShareableList(sl, name='test03_duplicate')
---
>         name_duplicate = self._new_shm_name('test03_duplicate')
>         sl_copy = shared_memory.ShareableList(sl, name=name_duplicate)
4088c4155
<             self.assertEqual('test03_duplicate', sl_copy.shm.name)
---
>             self.assertEqual(name_duplicate, sl_copy.shm.name)
4120,4139c4187,4222
<         sl = shared_memory.ShareableList(range(10))
<         self.addCleanup(sl.shm.unlink)
< 
<         serialized_sl = pickle.dumps(sl)
<         deserialized_sl = pickle.loads(serialized_sl)
<         self.assertTrue(
<             isinstance(deserialized_sl, shared_memory.ShareableList)
<         )
<         self.assertTrue(deserialized_sl[-1], 9)
<         self.assertFalse(sl is deserialized_sl)
<         deserialized_sl[4] = "changed"
<         self.assertEqual(sl[4], "changed")
< 
<         # Verify data is not being put into the pickled representation.
<         name = 'a' * len(sl.shm.name)
<         larger_sl = shared_memory.ShareableList(range(400))
<         self.addCleanup(larger_sl.shm.unlink)
<         serialized_larger_sl = pickle.dumps(larger_sl)
<         self.assertTrue(len(serialized_sl) == len(serialized_larger_sl))
<         larger_sl.shm.close()
---
>         for proto in range(pickle.HIGHEST_PROTOCOL + 1):
>             with self.subTest(proto=proto):
>                 sl = shared_memory.ShareableList(range(10))
>                 self.addCleanup(sl.shm.unlink)
> 
>                 serialized_sl = pickle.dumps(sl, protocol=proto)
>                 deserialized_sl = pickle.loads(serialized_sl)
>                 self.assertIsInstance(
>                     deserialized_sl, shared_memory.ShareableList)
>                 self.assertEqual(deserialized_sl[-1], 9)
>                 self.assertIsNot(sl, deserialized_sl)
> 
>                 deserialized_sl[4] = "changed"
>                 self.assertEqual(sl[4], "changed")
>                 sl[3] = "newvalue"
>                 self.assertEqual(deserialized_sl[3], "newvalue")
> 
>                 larger_sl = shared_memory.ShareableList(range(400))
>                 self.addCleanup(larger_sl.shm.unlink)
>                 serialized_larger_sl = pickle.dumps(larger_sl, protocol=proto)
>                 self.assertEqual(len(serialized_sl), len(serialized_larger_sl))
>                 larger_sl.shm.close()
> 
>                 deserialized_sl.shm.close()
>                 sl.shm.close()
> 
>     def test_shared_memory_ShareableList_pickling_dead_object(self):
>         for proto in range(pickle.HIGHEST_PROTOCOL + 1):
>             with self.subTest(proto=proto):
>                 sl = shared_memory.ShareableList(range(10))
>                 serialized_sl = pickle.dumps(sl, protocol=proto)
> 
>                 # Now, we are going to kill the original object.
>                 # So, unpickled one won't be able to attach to it.
>                 sl.shm.close()
>                 sl.shm.unlink()
4141,4142c4224,4225
<         deserialized_sl.shm.close()
<         sl.shm.close()
---
>                 with self.assertRaises(FileNotFoundError):
>                     pickle.loads(serialized_sl)
4178a4262,4268
>                 # Without this line it was raising warnings like:
>                 #   UserWarning: resource_tracker:
>                 #   There appear to be 1 leaked shared_memory
>                 #   objects to clean up at shutdown
>                 # See: https://bugs.python.org/issue45209
>                 resource_tracker.unregister(f"/{name}", "shared_memory")
> 
4188c4278
< #
---
> # Test to verify that `Finalize` works.
4199a4290
>         gc.collect()  # For PyPy or other GCs.
4210a4302
>         gc.collect()  # For PyPy or other GCs.
4216a4309
>         gc.collect()  # For PyPy or other GCs.
g
# ----------------------------------------------------------------------
diff Python-3.11.0a1/Lib/test/_test_multiprocessing.py py3.11/multiprocess/tests/__init__.py
3821c3825
<             'multiprocessing.shared_memory._make_filename') as mock_make_filename:
---
>             'multiprocess.shared_memory._make_filename') as mock_make_filename:
3898c3902
<             'multiprocessing.shared_memory._make_filename') as mock_make_filename:
---
>             'multiprocess.shared_memory._make_filename') as mock_make_filename:
# ----------------------------------------------------------------------
diff Python-3.11.0a1/Modules/_multiprocessing/multiprocessing.c Python-3.11.0a3/Modules/_multiprocessing/multiprocessing.c
189,190c189
< #if defined(MS_WINDOWS) ||                                              \
<   (defined(HAVE_SEM_OPEN) && !defined(POSIX_SEMAPHORES_NOT_ENABLED))
---
> #ifdef HAVE_MP_SEMAPHORE
diff Python-3.11.0a1/Modules/_multiprocessing/multiprocessing.h Python-3.11.0a3/Modules/_multiprocessing/multiprocessing.h
23a24
> #  define HAVE_MP_SEMAPHORE
26a28
> #    define HAVE_MP_SEMAPHORE
diff Python-3.11.0a1/Modules/_multiprocessing/semaphore.c Python-3.11.0a3/Modules/_multiprocessing/semaphore.c
11a12,13
> #ifdef HAVE_MP_SEMAPHORE
> 
796a799,800
> 
> #endif // HAVE_MP_SEMAPHORE
# ----------------------------------------------------------------------
cp Python-3.11.0a3/Modules/_multiprocessing/clinic/* py3.11/Modules/_multiprocess/clinic
# ----------------------------------------------------------------------
diff Python-3.11.0a3/Lib/multiprocessing/synchronize.py Python-3.11.0a4/Lib/multiprocessing/synchronize.py
355a356,358
>     def __repr__(self) -> str:
>         set_status = 'set' if self.is_set() else 'unset'
>         return f"<{type(self).__qualname__} at {id(self):#x} {set_status}>"
diff Python-3.11.0a3/Lib/test/_test_multiprocessing.py Python-3.11.0a4/Lib/test/_test_multiprocessing.py 
1648c1648,1661
< #
---
>     def test_repr(self) -> None:
>         event = self.Event()
>         if self.TYPE == 'processes':
>             self.assertRegex(repr(event), r"<Event at .* unset>")
>             event.set()
>             self.assertRegex(repr(event), r"<Event at .* set>")
>             event.clear()
>             self.assertRegex(repr(event), r"<Event at .* unset>")
>         elif self.TYPE == 'manager':
>             self.assertRegex(repr(event), r"<EventProxy object, typeid 'Event' at .*")
>             event.set()
>             self.assertRegex(repr(event), r"<EventProxy object, typeid 'Event' at .*")
> 
> 
# ----------------------------------------------------------------------
diff Python-3.11.0a4/Lib/multiprocessing/managers.py Python-3.11.0a5/Lib/multiprocessing/managers.py
52,56c52,56
< if view_types[0] is not list:       # only needed in Py3.0
<     def rebuild_as_list(obj):
<         return list, (list(obj),)
<     for view_type in view_types:
<         reduction.register(view_type, rebuild_as_list)
---
> def rebuild_as_list(obj):
>     return list, (list(obj),)
> for view_type in view_types:
>     reduction.register(view_type, rebuild_as_list)
> del view_type, view_types
diff Python-3.11.0a4/Lib/multiprocessing/process.py Python-3.11.0a5/Lib/multiprocessing/process.py
429a430
> del name, signum
# ----------------------------------------------------------------------
diff Python-3.11.0a5/Lib/test/_test_multiprocessing.py Python-3.11.0a7/Lib/test/_test_multiprocessing.py 
75a76,81
> if support.check_sanitizer(address=True):
>     # bpo-45200: Skip multiprocessing tests if Python is built with ASAN to
>     # work around a libasan race condition: dead lock in pthread_create().
>     raise unittest.SkipTest("libasan has a pthread_create() dead lock")
> 
> 
249a256,279
>     def test_args_argument(self):
>         # bpo-45735: Using list or tuple as *args* in constructor could
>         # achieve the same effect.
>         args_cases = (1, "str", [1], (1,))
>         args_types = (list, tuple)
> 
>         test_cases = itertools.product(args_cases, args_types)
> 
>         for args, args_type in test_cases:
>             with self.subTest(args=args, args_type=args_type):
>                 q = self.Queue(1)
>                 # pass a tuple or list as args
>                 p = self.Process(target=self._test_args, args=args_type((q, args)))
>                 p.daemon = True
>                 p.start()
>                 child_args = q.get()
>                 self.assertEqual(child_args, args)
>                 p.join()
>                 close_queue(q)
> 
>     @classmethod
>     def _test_args(cls, q, arg):
>         q.put(arg)
> 
# ----------------------------------------------------------------------
diff Python-3.11.0a7/Lib/multiprocessing/connection.py Python-3.11.0b1/Lib/multiprocessing/connection.py
191d190
<         # HACK for byte-indexing of non-bytewise buffers (e.g. array.array)
193,194c192,193
<             m = memoryview(bytes(m))
<         n = len(m)
---
>             m = m.cast('B')
>         n = m.nbytes
Common subdirectories: Python-3.11.0a7/Lib/multiprocessing/dummy and Python-3.11.0b1/Lib/multiprocessing/dummy
diff Python-3.11.0a7/Lib/multiprocessing/managers.py Python-3.11.0b1/Lib/multiprocessing/managers.py
500c500
<                  ctx=None):
---
>                  ctx=None, *, shutdown_timeout=1.0):
509a510
>         self._shutdown_timeout = shutdown_timeout
573,574c574,575
<             args=(self._process, self._address, self._authkey,
<                   self._state, self._Client),
---
>             args=(self._process, self._address, self._authkey, self._state,
>                   self._Client, self._shutdown_timeout),
659c660,661
<     def _finalize_manager(process, address, authkey, state, _Client):
---
>     def _finalize_manager(process, address, authkey, state, _Client,
>                           shutdown_timeout):
674c676
<             process.join(timeout=1.0)
---
>             process.join(timeout=shutdown_timeout)
680c682
<                     process.join(timeout=0.1)
---
>                     process.join(timeout=shutdown_timeout)
682a685,686
>                         process.kill()
>                         process.join()
diff Python-3.11.0a7/Lib/multiprocessing/queues.py Python-3.11.0b1/Lib/multiprocessing/queues.py
142,148c142,145
<         try:
<             self._reader.close()
<         finally:
<             close = self._close
<             if close:
<                 self._close = None
<                 close()
---
>         close = self._close
>         if close:
>             self._close = None
>             close()
172,173c169,171
<                   self._wlock, self._writer.close, self._ignore_epipe,
<                   self._on_queue_feeder_error, self._sem),
---
>                   self._wlock, self._reader.close, self._writer.close,
>                   self._ignore_epipe, self._on_queue_feeder_error,
>                   self._sem),
214,215c212,213
<     def _feed(buffer, notempty, send_bytes, writelock, close, ignore_epipe,
<               onerror, queue_sem):
---
>     def _feed(buffer, notempty, send_bytes, writelock, reader_close,
>               writer_close, ignore_epipe, onerror, queue_sem):
241c239,240
<                             close()
---
>                             reader_close()
>                             writer_close()
diff Python-3.11.0a7/Lib/multiprocessing/spawn.py Python-3.11.0b1/Lib/multiprocessing/spawn.py
36,40d35
< if WINSERVICE:
<     _python_exe = os.path.join(sys.exec_prefix, 'python.exe')
< else:
<     _python_exe = sys.executable
< 
43c38,41
<     _python_exe = exe
---
>     if sys.platform == 'win32':
>         _python_exe = os.fsdecode(exe)
>     else:
>         _python_exe = os.fsencode(exe)
47a46,50
> if WINSERVICE:
>     set_executable(os.path.join(sys.exec_prefix, 'python.exe'))
> else:
>     set_executable(sys.executable)
> 
89c92,93
<         return [_python_exe] + opts + ['-c', prog, '--multiprocessing-fork']
---
>         exe = get_executable()
>         return [exe] + opts + ['-c', prog, '--multiprocessing-fork']
diff Python-3.11.0a7/Lib/multiprocessing/util.py Python-3.11.0b1/Lib/multiprocessing/util.py
123c123
<     raise TypeError('address type of {address!r} unrecognized')
---
>     raise TypeError(f'address type of {address!r} unrecognized')
448a449
>     import subprocess
453c454
<             args, [os.fsencode(path)], True, passfds, None, None,
---
>             args, [path], True, passfds, None, None,
455c456,457
<             False, False, None, None, None, -1, None)
---
>             False, False, -1, None, None, None, -1, None,
>             subprocess._USE_VFORK)
# ----------------------------------------------------------------------
diff Python-3.11.0b1/Lib/multiprocessing/context.py Python-3.11.0b5/Lib/multiprocessing/context.py
225a226,229
>     @staticmethod
>     def _after_fork():
>         return _default_context.get_context().Process._after_fork()
> 
285a290,294
>         @staticmethod
>         def _after_fork():
>             # process is spawned, nothing to do
>             pass
> 
328a338,342
>         @staticmethod
>         def _after_fork():
>             # process is spawned, nothing to do
>             pass
> 
Common subdirectories: Python-3.11.0b1/Lib/multiprocessing/dummy and Python-3.11.0b5/Lib/multiprocessing/dummy
diff Python-3.11.0b1/Lib/multiprocessing/pool.py Python-3.11.0b5/Lib/multiprocessing/pool.py
205a206,208
>         if maxtasksperchild is not None:
>             if not isinstance(maxtasksperchild, int) or maxtasksperchild <= 0:
>                 raise ValueError("maxtasksperchild must be a positive int or None")
diff Python-3.11.0b1/Lib/multiprocessing/process.py Python-3.11.0b5/Lib/multiprocessing/process.py
307,308c307
<                 util._finalizer_registry.clear()
<                 util._run_after_forkers()
---
>                 self._after_fork()
338a338,344
>     @staticmethod
>     def _after_fork():
>         from . import util
>         util._finalizer_registry.clear()
>         util._run_after_forkers()
> 
> 
diff Python-3.11.0b1/Lib/multiprocessing/shared_memory.py Python-3.11.0b5/Lib/multiprocessing/shared_memory.py
25a26
> from . import resource_tracker
119,120c120
<             from .resource_tracker import register
<             register(self._name, "shared_memory")
---
>             resource_tracker.register(self._name, "shared_memory")
240d239
<             from .resource_tracker import unregister
242c241
<             unregister(self._name, "shared_memory")
---
>             resource_tracker.unregister(self._name, "shared_memory")
diff Python-3.11.0b1/Modules/_multiprocessing/semaphore.c Python-3.11.0b5/Modules/_multiprocessing/semaphore.c
457,459c457
<     SemLockObject *self;
< 
<     self = PyObject_New(SemLockObject, type);
---
>     SemLockObject *self = (SemLockObject *)type->tp_alloc(type, 0);
576c574
<     PyObject_Free(self);
---
>     Py_TYPE(self)->tp_free((PyObject*)self);
diff Python-3.11.0b1/Lib/test/_test_multiprocessing.py Python-3.11.0b5/Lib/test/_test_multiprocessing.py 
7a8
> import textwrap
2862a2864,2868
>     def test_pool_maxtasksperchild_invalid(self):
>         for value in [0, -1, 0.5, "12"]:
>             with self.assertRaises(ValueError):
>                 multiprocessing.Pool(3, maxtasksperchild=value)
> 
3968c3974
<             names = ['test01_fn', 'test02_fn']
---
>             names = [self._new_shm_name('test03_fn'), self._new_shm_name('test04_fn')]
5762a5769,5797
> class TestNamedResource(unittest.TestCase):
>     def test_global_named_resource_spawn(self):
>         #
>         # gh-90549: Check that global named resources in main module
>         # will not leak by a subprocess, in spawn context.
>         #
>         testfn = os_helper.TESTFN
>         self.addCleanup(os_helper.unlink, testfn)
>         with open(testfn, 'w', encoding='utf-8') as f:
>             f.write(textwrap.dedent('''\
>                 import multiprocessing as mp
> 
>                 ctx = mp.get_context('spawn')
> 
>                 global_resource = ctx.Semaphore()
> 
>                 def submain(): pass
> 
>                 if __name__ == '__main__':
>                     p = ctx.Process(target=submain)
>                     p.start()
>                     p.join()
>             '''))
>         rc, out, err = test.support.script_helper.assert_python_ok(testfn)
>         # on error, err = 'UserWarning: resource_tracker: There appear to
>         # be 1 leaked semaphore objects to clean up at shutdown'
>         self.assertEqual(err, b'')
> 
> 
5993a6029,6040
> 
> 
> @unittest.skipIf(not hasattr(_multiprocessing, 'SemLock'), 'SemLock not available')
> @unittest.skipIf(sys.platform != "linux", "Linux only")
> class SemLockTests(unittest.TestCase):
> 
>     def test_semlock_subclass(self):
>         class SemLock(_multiprocessing.SemLock):
>             pass
>         name = f'test_semlock_subclass-{os.getpid()}'
>         s = SemLock(1, 0, 10, name, 0)
>         _multiprocessing.sem_unlink(name)
# ----------------------------------------------------------------------
diff Python-3.11.0b5/Lib/multiprocessing/connection.py Python-3.11.0/Lib/multiprocessing/connection.py
76,80d75
<         # Prefer abstract sockets if possible to avoid problems with the address
<         # size.  When coding portable applications, some implementations have
<         # sun_path as short as 92 bytes in the sockaddr_un struct.
<         if util.abstract_sockets_supported:
<             return f"\0listener-{os.getpid()}-{next(_mmap_counter)}"
diff Python-3.11.0b5/Lib/multiprocessing/popen_spawn_win32.py Python-3.11.0/Lib/multiprocessing/popen_spawn_win32.py
57d56
<         cmd = ' '.join('"%s"' % x for x in cmd)
64c63
<             python_exe = sys._base_executable
---
>             cmd[0] = python_exe = sys._base_executable
69a69,70
>         cmd = ' '.join('"%s"' % x for x in cmd)
> 
# ----------------------------------------------------------------------
cp Python-3.11.0/Modules/_multiprocessing/clinic/* Modules/_multiprocess/clinic/
# ----------------------------------------------------------------------
diff Python-3.11.0/Lib/multiprocessing/resource_tracker.py Python-3.11.1/Lib/multiprocessing/resource_tracker.py
164c164
<         if len(name) > 512:
---
>         if len(msg) > 512:
167c167
<             raise ValueError('name too long')
---
>             raise ValueError('msg too long')
diff Python-3.11.0/Lib/multiprocessing/shared_memory.py Python-3.11.1/Lib/multiprocessing/shared_memory.py
176c176,179
<                 size = _winapi.VirtualQuerySize(p_buf)
---
>                 try:
>                     size = _winapi.VirtualQuerySize(p_buf)
>                 finally:
>                     _winapi.UnmapViewOfFile(p_buf)
diff Python-3.11.0/Lib/test/_test_multiprocessing.py Python-3.11.1/Lib/test/_test_multiprocessing.py 
5440a5441,5448
>     def test_too_long_name_resource(self):
>         # gh-96819: Resource names that will make the length of a write to a pipe
>         # greater than PIPE_BUF are not allowed
>         rtype = "shared_memory"
>         too_long_name_resource = "a" * (512 - len(rtype))
>         with self.assertRaises(ValueError):
>             resource_tracker.register(too_long_name_resource, rtype)
> 
6039c6047
<         s = SemLock(1, 0, 10, name, 0)
---
>         s = SemLock(1, 0, 10, name, False)
# ----------------------------------------------------------------------
diff Python-3.11.1/Lib/multiprocessing/process.py Python-3.11.4/Lib/multiprocessing/process.py
64c64
<         if p._popen.poll() is not None:
---
>         if (child_popen := p._popen) and child_popen.poll() is not None:
